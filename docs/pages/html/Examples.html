<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Classification Examples &mdash; hgboost hgboost documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="_static/doctools.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Sponsor" href="Documentation.html" />
    <link rel="prev" title="Save and Load" href="Save%20and%20Load.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> hgboost
          </a>
              <div class="version">
                1.1.3
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
    
              <p class="caption" role="heading"><span class="caption-text">Background</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Abstract.html">Abstract</a></li>
<li class="toctree-l1"><a class="reference internal" href="Abstract.html#schematic-overview">Schematic overview</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="Installation.html#quickstart">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="Installation.html#uninstalling">Uninstalling</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Background</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Algorithms.html">Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="Cross%20validation%20and%20hyperparameter%20tuning.html">Splitting the data set</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Methods</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Classification.html">Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="Regression.html">Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="Performance.html">Performance</a></li>
<li class="toctree-l1"><a class="reference internal" href="Save%20and%20Load.html">Save and Load</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Classification Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#xgboost-two-class">xgboost two-class</a></li>
<li class="toctree-l2"><a class="reference internal" href="#catboost">catboost</a></li>
<li class="toctree-l2"><a class="reference internal" href="#lightboost">lightboost</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#multi-classification-examples">Multi-classification Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#xgboost-multi-class">xgboost multi-class</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#regression-examples">Regression Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#xgboost-reg">xgboost_reg</a></li>
<li class="toctree-l2"><a class="reference internal" href="#lightboost-reg">lightboost_reg</a></li>
<li class="toctree-l2"><a class="reference internal" href="#catboost-reg">catboost_reg</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#ensemble-examples">Ensemble Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#ensemble-classification">Ensemble Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ensemble-regression">Ensemble Regression</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#plots">Plots</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#plot-params">plot_params</a></li>
<li class="toctree-l2"><a class="reference internal" href="#plot-summary">plot summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="#treeplot">treeplot</a></li>
<li class="toctree-l2"><a class="reference internal" href="#plot-validation">plot_validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#plot-cv">plot_cv</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Documentation.html">Sponsor</a></li>
<li class="toctree-l1"><a class="reference internal" href="Documentation.html#medium-blog">Medium Blog</a></li>
<li class="toctree-l1"><a class="reference internal" href="Documentation.html#github">Github</a></li>
<li class="toctree-l1"><a class="reference internal" href="Documentation.html#colab-classification-notebook">Colab Classification Notebook</a></li>
<li class="toctree-l1"><a class="reference internal" href="Documentation.html#colab-regression-notebook">Colab Regression Notebook</a></li>
<li class="toctree-l1"><a class="reference internal" href="Documentation.html#citing">Citing</a></li>
<li class="toctree-l1"><a class="reference internal" href="Coding%20quality.html">Coding quality</a></li>
<li class="toctree-l1"><a class="reference internal" href="hgboost.hgboost.html">API References</a></li>
</ul>

    <a href= "genindex.html">Index</a>
  
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">hgboost</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Classification Examples</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/Examples.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <hr>
<center>
        <script async src="https://media.ethicalads.io/media/client/ethicalads.min.js"></script>
        <!-- Show an image ad -->
        <!-- <div data-ea-publisher="erdogantgithubio" data-ea-type="image"></div> -->
        <div data-ea-publisher="erdogantgithubio" data-ea-type="text"></div>
</center>
<hr><section id="classification-examples">
<h1>Classification Examples<a class="headerlink" href="#classification-examples" title="Permalink to this heading"></a></h1>
<p>Some of the described examples can also be found in the Colab notebooks:
See <a class="reference external" href="https://colab.research.google.com/github/erdogant/hgboost/blob/master/notebooks/hgboost_classification_examples.ipynb">classification Colab notebook</a>.</p>
<section id="xgboost-two-class">
<h2>xgboost two-class<a class="headerlink" href="#xgboost-two-class" title="Permalink to this heading"></a></h2>
<p>Function documentation can be found here <a class="reference internal" href="hgboost.hgboost.html#hgboost.hgboost.hgboost.xgboost" title="hgboost.hgboost.hgboost.xgboost"><code class="xref py py-func docutils literal notranslate"><span class="pre">hgboost.hgboost.hgboost.xgboost()</span></code></a></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import library</span>
<span class="kn">from</span> <span class="nn">hgboost</span> <span class="kn">import</span> <span class="n">hgboost</span>

<span class="c1"># Initialize</span>
<span class="n">hgb</span> <span class="o">=</span> <span class="n">hgboost</span><span class="p">(</span><span class="n">max_eval</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">val_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">top_cv_evals</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># Load example data set</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">hgb</span><span class="o">.</span><span class="n">import_example</span><span class="p">()</span>
<span class="c1"># Prepare data for classification</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Survived&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="k">del</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Survived&#39;</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">hgb</span><span class="o">.</span><span class="n">preprocessing</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Fit best model with desired evaluation metric:</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">hgb</span><span class="o">.</span><span class="n">xgboost</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">eval_metric</span><span class="o">=</span><span class="s1">&#39;f1&#39;</span><span class="p">)</span>
<span class="c1"># [hgboost] &gt;Start hgboost classification..</span>
<span class="c1"># [hgboost] &gt;Collecting xgb_clf parameters.</span>
<span class="c1"># [hgboost] &gt;Number of variables in search space is [10], loss function: [f1].</span>
<span class="c1"># [hgboost] &gt;method: xgb_clf</span>
<span class="c1"># [hgboost] &gt;eval_metric: f1</span>
<span class="c1"># [hgboost] &gt;greater_is_better: True</span>
<span class="c1"># [hgboost] &gt;Total dataset: (891, 204)</span>
<span class="c1"># [hgboost] &gt;Hyperparameter optimization..</span>

<span class="c1"># Plot the parameter space</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">plot_params</span><span class="p">()</span>
<span class="c1"># Plot the summary results</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="c1"># Plot the best performing tree</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">treeplot</span><span class="p">()</span>
<span class="c1"># Plot results on the validation set</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">plot_validation</span><span class="p">()</span>
<span class="c1"># Plot results on the cross-validation</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">plot_cv</span><span class="p">()</span>

<span class="c1"># Make new prdiction using the model (suppose that X is new and unseen data which is similarly prepared as for the learning process)</span>
<span class="n">y_pred</span><span class="p">,</span> <span class="n">y_proba</span> <span class="o">=</span> <span class="n">hgb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="catboost">
<h2>catboost<a class="headerlink" href="#catboost" title="Permalink to this heading"></a></h2>
<p>Function documentation can be found here <a class="reference internal" href="hgboost.hgboost.html#hgboost.hgboost.hgboost.catboost" title="hgboost.hgboost.hgboost.catboost"><code class="xref py py-func docutils literal notranslate"><span class="pre">hgboost.hgboost.hgboost.catboost()</span></code></a></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import library</span>
<span class="kn">from</span> <span class="nn">hgboost</span> <span class="kn">import</span> <span class="n">hgboost</span>

<span class="c1"># Initialize</span>
<span class="n">hgb</span> <span class="o">=</span> <span class="n">hgboost</span><span class="p">(</span><span class="n">max_eval</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">val_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">top_cv_evals</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># Load example data set</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">hgb</span><span class="o">.</span><span class="n">import_example</span><span class="p">()</span>
<span class="c1"># Prepare data for classification</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Survived&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="k">del</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Survived&#39;</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">hgb</span><span class="o">.</span><span class="n">preprocessing</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Fit best model with desired evaluation metric:</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">hgb</span><span class="o">.</span><span class="n">catboost</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">eval_metric</span><span class="o">=</span><span class="s1">&#39;auc&#39;</span><span class="p">)</span>
<span class="c1"># [hgboost] &gt;Start hgboost classification..</span>
<span class="c1"># [hgboost] &gt;Collecting ctb_clf parameters.</span>
<span class="c1"># [hgboost] &gt;Number of variables in search space is [10], loss function: [auc].</span>
<span class="c1"># [hgboost] &gt;method: ctb_clf</span>
<span class="c1"># [hgboost] &gt;eval_metric: auc</span>
<span class="c1"># [hgboost] &gt;greater_is_better: True</span>
<span class="c1"># [hgboost] &gt;Total dataset: (891, 204)</span>
<span class="c1"># [hgboost] &gt;Hyperparameter optimization..</span>

<span class="c1"># Plot the parameter space</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">plot_params</span><span class="p">()</span>
<span class="c1"># Plot the summary results</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="c1"># Plot the best performing tree</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">treeplot</span><span class="p">()</span>
<span class="c1"># Plot results on the validation set</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">plot_validation</span><span class="p">()</span>
<span class="c1"># Plot results on the cross-validation</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">plot_cv</span><span class="p">()</span>

<span class="c1"># Make new prdiction using the model (suppose that X is new and unseen data which is similarly prepared as for the learning process)</span>
<span class="n">y_pred</span><span class="p">,</span> <span class="n">y_proba</span> <span class="o">=</span> <span class="n">hgb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="lightboost">
<h2>lightboost<a class="headerlink" href="#lightboost" title="Permalink to this heading"></a></h2>
<p>Function documentation can be found here <a class="reference internal" href="hgboost.hgboost.html#hgboost.hgboost.hgboost.lightboost" title="hgboost.hgboost.hgboost.lightboost"><code class="xref py py-func docutils literal notranslate"><span class="pre">hgboost.hgboost.hgboost.lightboost()</span></code></a></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import library</span>
<span class="kn">from</span> <span class="nn">hgboost</span> <span class="kn">import</span> <span class="n">hgboost</span>

<span class="c1"># Initialize</span>
<span class="n">hgb</span> <span class="o">=</span> <span class="n">hgboost</span><span class="p">(</span><span class="n">max_eval</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">val_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">top_cv_evals</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># Load example data set</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">hgb</span><span class="o">.</span><span class="n">import_example</span><span class="p">()</span>
<span class="c1"># Prepare data for classification</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Survived&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="k">del</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Survived&#39;</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">hgb</span><span class="o">.</span><span class="n">preprocessing</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Fit best model with desired evaluation metric:</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">hgb</span><span class="o">.</span><span class="n">lightboost</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">eval_metric</span><span class="o">=</span><span class="s1">&#39;auc&#39;</span><span class="p">)</span>
<span class="c1"># [hgboost] &gt;Start hgboost classification..</span>
<span class="c1"># [hgboost] &gt;Collecting lgb_clf parameters.</span>
<span class="c1"># [hgboost] &gt;Number of variables in search space is [10], loss function: [auc].</span>
<span class="c1"># [hgboost] &gt;method: lgb_clf</span>
<span class="c1"># [hgboost] &gt;eval_metric: auc</span>
<span class="c1"># [hgboost] &gt;greater_is_better: True</span>
<span class="c1"># [hgboost] &gt;Total dataset: (891, 204)</span>
<span class="c1"># [hgboost] &gt;Hyperparameter optimization..</span>

<span class="c1"># Plot the parameter space</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">plot_params</span><span class="p">()</span>
<span class="c1"># Plot the summary results</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="c1"># Plot the best performing tree</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">treeplot</span><span class="p">()</span>
<span class="c1"># Plot results on the validation set</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">plot_validation</span><span class="p">()</span>
<span class="c1"># Plot results on the cross-validation</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">plot_cv</span><span class="p">()</span>

<span class="c1"># Make new prdiction using the model (suppose that X is new and unseen data which is similarly prepared as for the learning process)</span>
<span class="n">y_pred</span><span class="p">,</span> <span class="n">y_proba</span> <span class="o">=</span> <span class="n">hgb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="multi-classification-examples">
<h1>Multi-classification Examples<a class="headerlink" href="#multi-classification-examples" title="Permalink to this heading"></a></h1>
<section id="xgboost-multi-class">
<h2>xgboost multi-class<a class="headerlink" href="#xgboost-multi-class" title="Permalink to this heading"></a></h2>
<p>Function documentation can be found here <a class="reference internal" href="hgboost.hgboost.html#hgboost.hgboost.hgboost.xgboost" title="hgboost.hgboost.hgboost.xgboost"><code class="xref py py-func docutils literal notranslate"><span class="pre">hgboost.hgboost.hgboost.xgboost()</span></code></a></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import library</span>
<span class="kn">from</span> <span class="nn">hgboost</span> <span class="kn">import</span> <span class="n">hgboost</span>

<span class="c1"># Initialize</span>
<span class="n">hgb</span> <span class="o">=</span> <span class="n">hgboost</span><span class="p">(</span><span class="n">max_eval</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">val_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">top_cv_evals</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># Load example data set</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">hgb</span><span class="o">.</span><span class="n">import_example</span><span class="p">()</span>
<span class="c1"># Prepare data for classification</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Parch&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">y</span><span class="p">[</span><span class="n">y</span><span class="o">&gt;=</span><span class="mi">3</span><span class="p">]</span><span class="o">=</span><span class="mi">3</span>
<span class="k">del</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Parch&#39;</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">hgb</span><span class="o">.</span><span class="n">preprocessing</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Fit best model with desired evaluation metric:</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">hgb</span><span class="o">.</span><span class="n">xgboost</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;xgb_clf_multi&#39;</span><span class="p">,</span> <span class="n">eval_metric</span><span class="o">=</span><span class="s1">&#39;kappa&#39;</span><span class="p">)</span>
<span class="c1"># [hgboost] &gt;Start hgboost classification..</span>
<span class="c1"># [hgboost] &gt;Collecting xgb_clf parameters</span>
<span class="c1"># [hgboost] &gt;Number of variables in search space is [10], loss function: [kappa]</span>
<span class="c1"># [hgboost] &gt;method: xgb_clf_multi</span>
<span class="c1"># [hgboost] &gt;eval_metric: kappa</span>
<span class="c1"># [hgboost] &gt;greater_is_better: True</span>
<span class="c1"># [hgboost] &gt;Total dataset: (891, 204)</span>
<span class="c1"># [hgboost] &gt;Hyperparameter optimization..</span>

<span class="c1"># Plot the parameter space</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">plot_params</span><span class="p">()</span>
<span class="c1"># Plot the summary results</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="c1"># Plot the best performing tree</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">treeplot</span><span class="p">()</span>
<span class="c1"># Plot results on the validation set</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">plot_validation</span><span class="p">()</span>
<span class="c1"># Plot results on the cross-validation</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">plot_cv</span><span class="p">()</span>

<span class="c1"># Make new prdiction using the model (suppose that X is new and unseen data which is similarly prepared as for the learning process)</span>
<span class="n">y_pred</span><span class="p">,</span> <span class="n">y_proba</span> <span class="o">=</span> <span class="n">hgb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="regression-examples">
<h1>Regression Examples<a class="headerlink" href="#regression-examples" title="Permalink to this heading"></a></h1>
<p>Some of the described examples can also be found in the notebooks:
See <a class="reference external" href="https://colab.research.google.com/github/erdogant/hgboost/blob/master/notebooks/hgboost_regression_examples.ipynb">regression Colab notebook</a>.</p>
<section id="xgboost-reg">
<h2>xgboost_reg<a class="headerlink" href="#xgboost-reg" title="Permalink to this heading"></a></h2>
<p>Function documentation can be found here <a class="reference internal" href="hgboost.hgboost.html#hgboost.hgboost.hgboost.xgboost_reg" title="hgboost.hgboost.hgboost.xgboost_reg"><code class="xref py py-func docutils literal notranslate"><span class="pre">hgboost.hgboost.hgboost.xgboost_reg()</span></code></a></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import library</span>
<span class="kn">from</span> <span class="nn">hgboost</span> <span class="kn">import</span> <span class="n">hgboost</span>

<span class="c1"># Initialize</span>
<span class="n">hgb</span> <span class="o">=</span> <span class="n">hgboost</span><span class="p">(</span><span class="n">max_eval</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">val_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">top_cv_evals</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

<span class="c1"># Load example data set</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">hgb</span><span class="o">.</span><span class="n">import_example</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Age&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="k">del</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Age&#39;</span><span class="p">]</span>
<span class="n">I</span> <span class="o">=</span> <span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">hgb</span><span class="o">.</span><span class="n">preprocessing</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">I</span><span class="p">,:]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">I</span><span class="p">]</span>

<span class="c1"># Fit best model with desired evaluation metric:</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">hgb</span><span class="o">.</span><span class="n">xgboost_reg</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">eval_metric</span><span class="o">=</span><span class="s1">&#39;rmse&#39;</span><span class="p">)</span>
<span class="c1"># [hgboost] &gt;Start hgboost regression..</span>
<span class="c1"># [hgboost] &gt;Collecting xgb_reg parameters.</span>
<span class="c1"># [hgboost] &gt;Number of variables in search space is [10], loss function: [rmse].</span>
<span class="c1"># [hgboost] &gt;method: xgb_reg</span>
<span class="c1"># [hgboost] &gt;eval_metric: rmse</span>
<span class="c1"># [hgboost] &gt;greater_is_better: True</span>
<span class="c1"># [hgboost] &gt;Total dataset: (891, 204)</span>
<span class="c1"># [hgboost] &gt;Hyperparameter optimization..</span>

<span class="c1"># Plot the parameter space</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">plot_params</span><span class="p">()</span>
<span class="c1"># Plot the summary results</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="c1"># Plot the best performing tree</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">treeplot</span><span class="p">()</span>
<span class="c1"># Plot results on the validation set</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">plot_validation</span><span class="p">()</span>
<span class="c1"># Plot results on the cross-validation</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">plot_cv</span><span class="p">()</span>

<span class="c1"># Make new prdiction using the model (suppose that X is new and unseen data which is similarly prepared as for the learning process)</span>
<span class="n">y_pred</span><span class="p">,</span> <span class="n">y_proba</span> <span class="o">=</span> <span class="n">hgb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="lightboost-reg">
<h2>lightboost_reg<a class="headerlink" href="#lightboost-reg" title="Permalink to this heading"></a></h2>
<p>Function documentation can be found here <a class="reference internal" href="hgboost.hgboost.html#hgboost.hgboost.hgboost.lightboost_reg" title="hgboost.hgboost.hgboost.lightboost_reg"><code class="xref py py-func docutils literal notranslate"><span class="pre">hgboost.hgboost.hgboost.lightboost_reg()</span></code></a></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import library</span>
<span class="kn">from</span> <span class="nn">hgboost</span> <span class="kn">import</span> <span class="n">hgboost</span>

<span class="c1"># Initialize</span>
<span class="n">hgb</span> <span class="o">=</span> <span class="n">hgboost</span><span class="p">(</span><span class="n">max_eval</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">val_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">top_cv_evals</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

<span class="c1"># Load example data set</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">hgb</span><span class="o">.</span><span class="n">import_example</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Age&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="k">del</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Age&#39;</span><span class="p">]</span>
<span class="n">I</span> <span class="o">=</span> <span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">hgb</span><span class="o">.</span><span class="n">preprocessing</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">I</span><span class="p">,:]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">I</span><span class="p">]</span>

<span class="c1"># Fit best model with desired evaluation metric:</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">hgb</span><span class="o">.</span><span class="n">lightboost_reg</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">eval_metric</span><span class="o">=</span><span class="s1">&#39;rmse&#39;</span><span class="p">)</span>
<span class="c1"># [hgboost] &gt;Start hgboost regression..</span>
<span class="c1"># [hgboost] &gt;Collecting lgb_reg parameters.</span>
<span class="c1"># [hgboost] &gt;Number of variables in search space is [10], loss function: [rmse].</span>
<span class="c1"># [hgboost] &gt;method: lgb_reg</span>
<span class="c1"># [hgboost] &gt;eval_metric: rmse</span>
<span class="c1"># [hgboost] &gt;greater_is_better: True</span>
<span class="c1"># [hgboost] &gt;Total dataset: (891, 204)</span>
<span class="c1"># [hgboost] &gt;Hyperparameter optimization..</span>

<span class="c1"># Plot the parameter space</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">plot_params</span><span class="p">()</span>
<span class="c1"># Plot the summary results</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="c1"># Plot the best performing tree</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">treeplot</span><span class="p">()</span>
<span class="c1"># Plot results on the validation set</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">plot_validation</span><span class="p">()</span>
<span class="c1"># Plot results on the cross-validation</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">plot_cv</span><span class="p">()</span>

<span class="c1"># Make new prdiction using the model (suppose that X is new and unseen data which is similarly prepared as for the learning process)</span>
<span class="n">y_pred</span><span class="p">,</span> <span class="n">y_proba</span> <span class="o">=</span> <span class="n">hgb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="catboost-reg">
<h2>catboost_reg<a class="headerlink" href="#catboost-reg" title="Permalink to this heading"></a></h2>
<p>Function documentation can be found here <a class="reference internal" href="hgboost.hgboost.html#hgboost.hgboost.hgboost.catboost_reg" title="hgboost.hgboost.hgboost.catboost_reg"><code class="xref py py-func docutils literal notranslate"><span class="pre">hgboost.hgboost.hgboost.catboost_reg()</span></code></a></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import library</span>
<span class="kn">from</span> <span class="nn">hgboost</span> <span class="kn">import</span> <span class="n">hgboost</span>

<span class="c1"># Initialize</span>
<span class="n">hgb</span> <span class="o">=</span> <span class="n">hgboost</span><span class="p">(</span><span class="n">max_eval</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">val_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">top_cv_evals</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

<span class="c1"># Load example data set</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">hgb</span><span class="o">.</span><span class="n">import_example</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Age&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="k">del</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Age&#39;</span><span class="p">]</span>
<span class="n">I</span> <span class="o">=</span> <span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">hgb</span><span class="o">.</span><span class="n">preprocessing</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">I</span><span class="p">,:]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">I</span><span class="p">]</span>

<span class="c1"># Fit best model with desired evaluation metric:</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">hgb</span><span class="o">.</span><span class="n">catboost_reg</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">eval_metric</span><span class="o">=</span><span class="s1">&#39;rmse&#39;</span><span class="p">)</span>
<span class="c1"># [hgboost] &gt;Start hgboost regression..</span>
<span class="c1"># [hgboost] &gt;Collecting ctb_reg parameters.</span>
<span class="c1"># [hgboost] &gt;Number of variables in search space is [10], loss function: [rmse].</span>
<span class="c1"># [hgboost] &gt;method: ctb_reg</span>
<span class="c1"># [hgboost] &gt;eval_metric: rmse</span>
<span class="c1"># [hgboost] &gt;greater_is_better: True</span>
<span class="c1"># [hgboost] &gt;Total dataset: (891, 204)</span>
<span class="c1"># [hgboost] &gt;Hyperparameter optimization..</span>

<span class="c1"># Plot the parameter space</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">plot_params</span><span class="p">()</span>
<span class="c1"># Plot the summary results</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="c1"># Plot the best performing tree</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">treeplot</span><span class="p">()</span>
<span class="c1"># Plot results on the validation set</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">plot_validation</span><span class="p">()</span>
<span class="c1"># Plot results on the cross-validation</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">plot_cv</span><span class="p">()</span>

<span class="c1"># Make new prdiction using the model (suppose that X is new and unseen data which is similarly prepared as for the learning process)</span>
<span class="n">y_pred</span><span class="p">,</span> <span class="n">y_proba</span> <span class="o">=</span> <span class="n">hgb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="ensemble-examples">
<h1>Ensemble Examples<a class="headerlink" href="#ensemble-examples" title="Permalink to this heading"></a></h1>
<p>An ensemble is that each of the fitted models, such as xgboost, lightboost and catboost is even further combined into one function.
The results are usually superior compared to single models. However, the model complexity increases and training time too.
An ensemble can be created for both classification and the regression models.
The function documentation can be found here <a class="reference internal" href="hgboost.hgboost.html#hgboost.hgboost.hgboost.ensemble" title="hgboost.hgboost.hgboost.ensemble"><code class="xref py py-func docutils literal notranslate"><span class="pre">hgboost.hgboost.hgboost.ensemble()</span></code></a></p>
<section id="ensemble-classification">
<h2>Ensemble Classification<a class="headerlink" href="#ensemble-classification" title="Permalink to this heading"></a></h2>
<p>It can be seen from the results that the ensemble classifier performs superior compared to all indiviudal models.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import library</span>
<span class="kn">from</span> <span class="nn">hgboost</span> <span class="kn">import</span> <span class="n">hgboost</span>

<span class="c1"># Initialize</span>
<span class="n">hgb</span> <span class="o">=</span> <span class="n">hgboost</span><span class="p">(</span><span class="n">max_eval</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">val_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">top_cv_evals</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># Import data</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">hgb</span><span class="o">.</span><span class="n">import_example</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Survived&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="k">del</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Survived&#39;</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">hgb</span><span class="o">.</span><span class="n">preprocessing</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Fit ensemble model using the three boosting methods. By default these are readily set.</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">hgb</span><span class="o">.</span><span class="n">ensemble</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># [hgboost] &gt;Create ensemble regression model..</span>
<span class="c1"># [hgboost] &gt;...</span>
<span class="c1"># [hgboost] &gt;Fit ensemble model with [soft] voting..</span>
<span class="c1"># [hgboost] &gt;Evalute [ensemble] model on independent validation dataset (179 samples, 20%)</span>
<span class="c1"># [hgboost] &gt;[Ensemble] [auc]: -0.9788 on independent validation dataset</span>
<span class="c1"># [hgboost] &gt;[xgb_clf]  [auc]: -0.8434 on independent validation dataset</span>
<span class="c1"># [hgboost] &gt;[ctb_clf]  [auc]: -0.8875 on independent validation dataset</span>
<span class="c1"># [hgboost] &gt;[lgb_clf]  [auc]: -0.8816 on independent validation dataset</span>

<span class="c1"># use the predictor</span>
<span class="n">y_pred</span><span class="p">,</span> <span class="n">y_proba</span> <span class="o">=</span> <span class="n">hgb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Plot</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">plot_validation</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="ensemble-regression">
<h2>Ensemble Regression<a class="headerlink" href="#ensemble-regression" title="Permalink to this heading"></a></h2>
<p>It can be seen from the results that the ensemble classifier performs superior compared to all indiviudal models.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import library</span>
<span class="kn">from</span> <span class="nn">hgboost</span> <span class="kn">import</span> <span class="n">hgboost</span>

<span class="c1"># Initialize</span>
<span class="n">hgb</span> <span class="o">=</span> <span class="n">hgboost</span><span class="p">(</span><span class="n">max_eval</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">val_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">top_cv_evals</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

<span class="c1"># Load example data set</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">hgb</span><span class="o">.</span><span class="n">import_example</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Age&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="k">del</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Age&#39;</span><span class="p">]</span>
<span class="n">I</span> <span class="o">=</span> <span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">hgb</span><span class="o">.</span><span class="n">preprocessing</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">I</span><span class="p">,:]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">I</span><span class="p">]</span>

<span class="c1"># Fit ensemble model using the three boosting methods:</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">hgb</span><span class="o">.</span><span class="n">ensemble</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">methods</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;xgb_reg&#39;</span><span class="p">,</span><span class="s1">&#39;ctb_reg&#39;</span><span class="p">,</span><span class="s1">&#39;lgb_reg&#39;</span><span class="p">])</span>
<span class="c1"># [hgboost] &gt;Create ensemble regression model..</span>
<span class="c1"># [hgboost] &gt;...</span>
<span class="c1"># [hgboost] &gt;Evalute [ensemble] model on independent validation dataset (143 samples, 20%).</span>
<span class="c1"># [hgboost] &gt;[Ensemble] [rmse]: 64.62 on independent validation dataset</span>
<span class="c1"># [hgboost] &gt;[xgb_reg]  [rmse]: 172.2 on independent validation dataset</span>
<span class="c1"># [hgboost] &gt;[ctb_reg]  [rmse]: 183 on independent validation dataset</span>
<span class="c1"># [hgboost] &gt;[lgb_reg]  [rmse]: 205.9 on independent validation dataset</span>

<span class="c1"># Make new prdiction using the model (suppose that X is new and unseen data which is similarly prepared as for the learning process)</span>
<span class="n">y_pred</span><span class="p">,</span> <span class="n">y_proba</span> <span class="o">=</span> <span class="n">hgb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Plot</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">plot_validation</span><span class="p">()</span>
</pre></div>
</div>
</section>
</section>
<section id="plots">
<h1>Plots<a class="headerlink" href="#plots" title="Permalink to this heading"></a></h1>
<p>For each model, the following 5 plots can be created:</p>
<section id="plot-params">
<h2>plot_params<a class="headerlink" href="#plot-params" title="Permalink to this heading"></a></h2>
<p>Figure 1 depicts the density of the specific parameter values. As an example, the <strong>gamma</strong> parameter shows that most iterations converges towards value <strong>0</strong>.
This may indicate that this parameter with this value has an important role in the in computing the optimal loss.
Figure 2 depicts the iterations performed for hyper-optimization per parameter. In case of <strong>colsample_bytree</strong> we see a convergence towards the range [0.5-0.7].</p>
<p>In both figures, the parameters for all fitted models are plotted together with the <strong>best</strong> performing models with and without the <strong>k-fold crossvalidation</strong>.
In addition, we also plot the top n performing models. The top performing models can be usefull to deeper examine the used parameter.</p>
<p>Function documentation can be found here <a class="reference internal" href="hgboost.hgboost.html#hgboost.hgboost.hgboost.plot_params" title="hgboost.hgboost.hgboost.plot_params"><code class="xref py py-func docutils literal notranslate"><span class="pre">hgboost.hgboost.hgboost.plot_params()</span></code></a></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot the parameter space</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">plot_params</span><span class="p">()</span>
</pre></div>
</div>
<table class="docutils align-center" id="id1">
<caption><span class="caption-text">Parameter plot</span><a class="headerlink" href="#id1" title="Permalink to this table"></a></caption>
<colgroup>
<col style="width: 100%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><img alt="figS1" src="_images/plot_params_clf_1.png" /></p></td>
</tr>
<tr class="row-even"><td><p><img alt="figS2" src="_images/plot_params_clf_2.png" /></p></td>
</tr>
</tbody>
</table>
</section>
<section id="plot-summary">
<h2>plot summary<a class="headerlink" href="#plot-summary" title="Permalink to this heading"></a></h2>
<p>This figure exists out of two subfigures. The top figure depicts all evaluated models with the loss score.
The <strong>best</strong> performing models with and without the <strong>k-fold crossvalidation</strong> are depicted together with the top n performing models.
The bottom figure depicts the train and test-error.
Function documentation can be found here <a class="reference internal" href="hgboost.hgboost.html#hgboost.hgboost.hgboost.plot" title="hgboost.hgboost.hgboost.plot"><code class="xref py py-func docutils literal notranslate"><span class="pre">hgboost.hgboost.hgboost.plot()</span></code></a></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot the summary results</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>
</div>
<table class="docutils align-center" id="id2">
<caption><span class="caption-text">Summary plot of the results.</span><a class="headerlink" href="#id2" title="Permalink to this table"></a></caption>
<colgroup>
<col style="width: 100%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><img alt="figS3" src="_images/plot_clf.png" /></p></td>
</tr>
</tbody>
</table>
</section>
<section id="treeplot">
<h2>treeplot<a class="headerlink" href="#treeplot" title="Permalink to this heading"></a></h2>
<p>Function documentation can be found here <a class="reference internal" href="hgboost.hgboost.html#hgboost.hgboost.hgboost.treeplot" title="hgboost.hgboost.hgboost.treeplot"><code class="xref py py-func docutils literal notranslate"><span class="pre">hgboost.hgboost.hgboost.treeplot()</span></code></a></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot the best performing tree</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">treeplot</span><span class="p">()</span>
</pre></div>
</div>
<table class="docutils align-center" id="id3">
<caption><span class="caption-text">Best performing tree.</span><a class="headerlink" href="#id3" title="Permalink to this table"></a></caption>
<colgroup>
<col style="width: 100%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><img alt="figS4" src="_images/treeplot_clf_1.png" /></p></td>
</tr>
<tr class="row-even"><td><p><img alt="figS5" src="_images/treeplot_clf_2.png" /></p></td>
</tr>
</tbody>
</table>
</section>
<section id="plot-validation">
<h2>plot_validation<a class="headerlink" href="#plot-validation" title="Permalink to this heading"></a></h2>
<p>Function documentation can be found here <a class="reference internal" href="hgboost.hgboost.html#hgboost.hgboost.hgboost.plot_validation" title="hgboost.hgboost.hgboost.plot_validation"><code class="xref py py-func docutils literal notranslate"><span class="pre">hgboost.hgboost.hgboost.plot_validation()</span></code></a></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot results on the validation set</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">plot_validation</span><span class="p">()</span>
</pre></div>
</div>
<table class="docutils align-center" id="id4">
<caption><span class="caption-text">Results on the validation set.</span><a class="headerlink" href="#id4" title="Permalink to this table"></a></caption>
<colgroup>
<col style="width: 100%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><img alt="figS6" src="_images/plot_validation_clf_1.png" /></p></td>
</tr>
</tbody>
</table>
<table class="docutils align-center" id="id5">
<caption><span class="caption-text">Results on the validation set.</span><a class="headerlink" href="#id5" title="Permalink to this table"></a></caption>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><img alt="figS7" src="_images/plot_validation_clf_2.png" /></p></td>
<td><p><img alt="figS8" src="_images/plot_validation_clf_3.png" /></p></td>
</tr>
</tbody>
</table>
</section>
<section id="plot-cv">
<h2>plot_cv<a class="headerlink" href="#plot-cv" title="Permalink to this heading"></a></h2>
<p>Function documentation can be found here <a class="reference internal" href="hgboost.hgboost.html#hgboost.hgboost.hgboost.plot_cv" title="hgboost.hgboost.hgboost.plot_cv"><code class="xref py py-func docutils literal notranslate"><span class="pre">hgboost.hgboost.hgboost.plot_cv()</span></code></a></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot results on the cross-validation</span>
<span class="n">hgb</span><span class="o">.</span><span class="n">plot_cv</span><span class="p">()</span>
</pre></div>
</div>
<table class="docutils align-center" id="id6">
<caption><span class="caption-text">results on the cross-validation.</span><a class="headerlink" href="#id6" title="Permalink to this table"></a></caption>
<colgroup>
<col style="width: 100%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><img alt="figS9" src="_images/plot_cv_clf.png" /></p></td>
</tr>
</tbody>
</table>
<hr>
<center>
        <script async src="https://media.ethicalads.io/media/client/ethicalads.min.js"></script>
        <!-- Show an image ad -->
        <div data-ea-publisher="erdogantgithubio" data-ea-type="image"></div>
        <!-- <div data-ea-publisher="erdogantgithubio" data-ea-type="text"></div> -->
</center>
<hr></section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="Save%20and%20Load.html" class="btn btn-neutral float-left" title="Save and Load" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="Documentation.html" class="btn btn-neutral float-right" title="Sponsor" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Erdogan Taskesen.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>